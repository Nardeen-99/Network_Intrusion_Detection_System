{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost\n",
    "! pip install imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "data = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "data = data.dropna()\n",
    "test = test.dropna()\n",
    "X = data.drop(['Segmentation','ID'],axis=1)\n",
    "y = data['Segmentation']\n",
    "\n",
    "X_test = test.drop(['Segmentation','ID'],axis=1)\n",
    "y_test = test['Segmentation']\n",
    "X=pd.get_dummies(X,drop_first=True)\n",
    "X_test = pd.get_dummies(X_test,drop_first=True)\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "scaler=preprocessing.StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.fit_transform(X_test)\n",
    "\n",
    "y= label_encoder.fit_transform(y)\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Define the search space\n",
    "param_grid = { \n",
    "    # Percentage of columns to be randomly samples for each tree.\n",
    "    \"colsample_bytree\": [ 0.3, 0.5 , 0.8 ],\n",
    "    # reg_alpha provides l1 regularization to the weight, higher values result in more conservative models\n",
    "    \"reg_alpha\": [0, 0.5, 1, 5],\n",
    "    # reg_lambda provides l2 regularization to the weight, higher values result in more conservative models\n",
    "    \"reg_lambda\": [0, 0.5, 1, 5]\n",
    "    }\n",
    "# Set up score\n",
    "scoring = ['recall']\n",
    "# Set up the k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "model_1= XGBClassifier(learning_rate=0.02, n_estimators=600)\n",
    "grid_search = GridSearchCV(estimator=model_1, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring=scoring, \n",
    "                           refit='recall', \n",
    "                           n_jobs=-1, \n",
    "                           cv=kfold, \n",
    "                           verbose=0)\n",
    "# Fit grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
